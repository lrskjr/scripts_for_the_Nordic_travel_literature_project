{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e576df8-cecf-4495-af11-273e043cdf4f",
   "metadata": {},
   "source": [
    "# PDF Text Extraction Script\n",
    "\n",
    "This notebook extracts text content and metadata from PDF files in the Nordic travel literature collection.\n",
    "\n",
    "**Purpose:**\n",
    "- Batch process multiple PDF files from the `literature pdf` folder\n",
    "- Extract page content and metadata (page numbers, source file) from each PDF\n",
    "- Save extracted data as CSV files for further analysis\n",
    "\n",
    "**Workflow:**\n",
    "1. Load PDF files using LangChain's PyPDFLoader\n",
    "2. Extract text content and metadata from each page\n",
    "3. Organize data into pandas DataFrames\n",
    "4. Export to CSV files in `literature csv_raw` folder\n",
    "\n",
    "**Input:** PDF files in `.\\literature pdf\\`\n",
    "\n",
    "**Output:** CSV files (one per PDF) in `.\\literature csv_raw\\` containing:\n",
    "- `page`: Page number\n",
    "- `source`: Source PDF filename\n",
    "- `page_content`: Extracted text content from each page\n",
    "\n",
    "**Dependencies:** langchain_community, pandas, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a5ee2d-b7ef-4e40-a4c4-ba984e9038dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import libraries\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "print ('Import libraries')\n",
    "\n",
    "# LangChain document loaders for PDF and EPUB processing\n",
    "from langchain_community.document_loaders import UnstructuredEPubLoader  # For EPUB files (if needed)\n",
    "from langchain.document_loaders import PyPDFLoader  # Main PDF loader\n",
    "\n",
    "# Data manipulation and file operations\n",
    "import pandas as pd  # For creating and managing DataFrames\n",
    "import os  # For file and directory operations\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm  # Display progress bars in Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414310f2-90ab-424d-ad2e-34b2cb152b05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract text from PDF and return data in a DataFrame\n",
    "def pdf_text_extract_from_file(pdf_file):\n",
    "    \"\"\"\n",
    "    Extract text content and metadata from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file (str): Path to the PDF file to process\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing page metadata and content with columns:\n",
    "                      - page: Page number\n",
    "                      - source: Source PDF filename\n",
    "                      - page_content: Extracted text from the page\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the PDF loader with page-by-page mode\n",
    "    # This loads each page as a separate document object\n",
    "    loader = PyPDFLoader(pdf_file, mode='page')\n",
    "    \n",
    "    # Load all pages from the PDF\n",
    "    # Returns a list of Document objects, one per page\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # Create an empty list to store individual page DataFrames\n",
    "    data_bucket = []\n",
    "    \n",
    "    # Iterate through each page document\n",
    "    for i in docs:\n",
    "        # Extract metadata (page number, source file, etc.)\n",
    "        meta_data = i.metadata\n",
    "        \n",
    "        # Extract the actual text content from the page\n",
    "        page_content = i.page_content\n",
    "        \n",
    "        # Create a DataFrame from the metadata dictionary\n",
    "        # The [meta_data] wraps it in a list to create a single-row DataFrame\n",
    "        df = pd.DataFrame.from_dict([meta_data])\n",
    "        \n",
    "        # Add the page content as a new column\n",
    "        df['page_content'] = page_content\n",
    "        \n",
    "        # Append this page's DataFrame to the collection\n",
    "        data_bucket.append(df)\n",
    "    \n",
    "    # Concatenate all page DataFrames into a single DataFrame\n",
    "    # ignore_index=True creates a new sequential index (0, 1, 2, ...)\n",
    "    book_data = pd.concat(data_bucket, ignore_index=True)\n",
    "    \n",
    "    # Return the complete book data\n",
    "    return book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0bf33-bcc5-4917-8ca5-3d7610007e4f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786564df63f34e0cb6ac67e8bb67e90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data from multiple pdf files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# BATCH PROCESSING: Extract all PDF files\n",
    "# ============================================\n",
    "\n",
    "# Define input and output directories\n",
    "departure_folder = r'.\\literature pdf'      # Source folder containing PDF files\n",
    "arrival_folder = r'.\\literature csv_raw'    # Destination folder for CSV output\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "# exist_ok=True prevents errors if the directory already exists\n",
    "os.makedirs(arrival_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all files in the PDF folder\n",
    "files_in_folder = os.listdir(departure_folder)\n",
    "\n",
    "# Process each file in the folder with a progress bar\n",
    "for file in tqdm(files_in_folder, desc='Extracting data from multiple pdf files', colour='blue'):\n",
    "    \n",
    "    # Construct the full path to the PDF file\n",
    "    file_path = os.path.join(departure_folder, file)\n",
    "    \n",
    "    # Extract text and metadata from the PDF using our function\n",
    "    # Returns a DataFrame with all pages from this book\n",
    "    book = pdf_text_extract_from_file(file_path)\n",
    "    \n",
    "    # Create the CSV filename by replacing .pdf extension with .csv\n",
    "    # str(file)[:-4] removes the last 4 characters (.pdf)\n",
    "    csv_file_name = str(file)[:-4] + '.csv'\n",
    "    \n",
    "    # Construct the full path for the output CSV file\n",
    "    csv_file_path = os.path.join(arrival_folder, csv_file_name)\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    # index=False prevents pandas from writing row numbers as a column\n",
    "    book.to_csv(csv_file_path, index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
