{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09d2b4a-3b95-448d-97b3-a4513c8425f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# EPUB Text Extraction Script\n",
    "\n",
    "This notebook extracts text content and metadata from EPUB files in the Nordic travel literature collection.\n",
    "\n",
    "**Purpose:**\n",
    "- Batch process multiple EPUB files from the `literature epub` folder\n",
    "- Extract element content and metadata (source file, element structure) from each EPUB\n",
    "- Save extracted data as CSV files for further analysis\n",
    "\n",
    "**Workflow:**\n",
    "1. Load EPUB files using LangChain's UnstructuredEPubLoader\n",
    "2. Extract text content and metadata from each element (chapters, sections, paragraphs)\n",
    "3. Organize data into pandas DataFrames\n",
    "4. Export to CSV files in `literature csv_raw` folder\n",
    "\n",
    "**Input:** EPUB files in `.\\literature epub\\`\n",
    "\n",
    "**Output:** CSV files (one per EPUB) in `.\\literature csv_raw\\` containing:\n",
    "- `source`: Source EPUB filename\n",
    "- `page_content`: Extracted text content from each element\n",
    "- Additional metadata fields depending on EPUB structure\n",
    "\n",
    "**Dependencies:** langchain_community, pandas, tqdm\n",
    "\n",
    "**Note:** EPUB files are processed as elements (structural components) rather than pages, as EPUBs are reflowable documents without fixed pagination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62777ba4-299c-4f9f-a0b6-9f9c034cc1dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import libraries\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "print ('import libraries')\n",
    "\n",
    "# LangChain document loaders for EPUB and PDF processing\n",
    "from langchain_community.document_loaders import UnstructuredEPubLoader  # Main EPUB loader\n",
    "from langchain.document_loaders import PyPDFLoader  # For PDF files (if needed)\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd  # For creating and managing DataFrames\n",
    "\n",
    "# Text processing and file operations\n",
    "import re  # Regular expressions for text cleaning (if needed)\n",
    "import os  # For file and directory operations\n",
    "import csv  # CSV file handling\n",
    "import json  # JSON data handling (if needed)\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm  # Display progress bars in Jupyter notebooks\n",
    "tqdm.pandas()  # Enable progress bars for pandas operations\n",
    "\n",
    "# Time tracking\n",
    "import time  # For measuring execution time (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5b93f7-4892-4c6a-bb71-1449f497912d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract text from EPUB and return data in a DataFrame\n",
    "def epub_text_extract_from_file(epub_file):\n",
    "    \"\"\"\n",
    "    Extract text content and metadata from an EPUB file.\n",
    "    \n",
    "    Args:\n",
    "        epub_file (str): Path to the EPUB file to process\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing element metadata and content with columns:\n",
    "                      - source: Source EPUB filename\n",
    "                      - page_content: Extracted text from each element\n",
    "                      - Additional metadata fields (varies by EPUB structure)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the EPUB loader with element-based mode\n",
    "    # mode=\"elements\" breaks the EPUB into structural components (chapters, sections, paragraphs)\n",
    "    # This provides more granular text extraction than loading the entire book at once\n",
    "    loader = UnstructuredEPubLoader(epub_file, mode=\"elements\")\n",
    "    \n",
    "    # Load all elements from the EPUB\n",
    "    # Returns a list of Document objects, one per structural element\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # Create an empty list to store individual element DataFrames\n",
    "    data_bucket = [] \n",
    "    \n",
    "    # Iterate through each element document\n",
    "    for i in docs:\n",
    "        # Extract metadata (source file, element type, etc.)\n",
    "        meta_data = i.metadata\n",
    "        \n",
    "        # Extract the actual text content from the element\n",
    "        page_content = i.page_content\n",
    "        \n",
    "        # Create a DataFrame from the metadata dictionary\n",
    "        # The [meta_data] wraps it in a list to create a single-row DataFrame\n",
    "        df = pd.DataFrame.from_dict([meta_data])\n",
    "        \n",
    "        # Add the element content as a new column\n",
    "        df['page_content'] = page_content\n",
    "        \n",
    "        # Append this element's DataFrame to the collection\n",
    "        data_bucket.append(df)\n",
    "    \n",
    "    # Check if we have any data to concatenate\n",
    "    if not data_bucket:\n",
    "        # Return an empty DataFrame if no elements were extracted\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Concatenate all element DataFrames into a single DataFrame\n",
    "    # ignore_index=True creates a new sequential index (0, 1, 2, ...)\n",
    "    book_data = pd.concat(data_bucket, ignore_index=True)\n",
    "    \n",
    "    # Return the complete book data\n",
    "    return book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700694d-7dac-46cb-9114-edf8c86c6dcb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4653739d570547b1a1f8bd343459b652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data from multiple epub files:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# BATCH PROCESSING: Extract all EPUB files\n",
    "# ============================================\n",
    "\n",
    "# Define input and output directories\n",
    "departure_folder = r'.\\literature epub'     # Source folder containing EPUB files\n",
    "arrival_folder = r'.\\literature csv_raw'    # Destination folder for CSV output\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "# exist_ok=True prevents errors if the directory already exists\n",
    "os.makedirs(arrival_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all files in the EPUB folder\n",
    "files_in_folder = os.listdir(departure_folder)\n",
    "\n",
    "# Process each file in the folder with a progress bar\n",
    "for file in tqdm(files_in_folder, desc='Extracting data from multiple epub files', colour='blue'):\n",
    "    \n",
    "    # Skip non-EPUB files (e.g., hidden files, directories)\n",
    "    if not file.lower().endswith('.epub'):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Construct the full path to the EPUB file\n",
    "        file_path = os.path.join(departure_folder, file)\n",
    "        \n",
    "        # Extract text and metadata from the EPUB using our function\n",
    "        # Returns a DataFrame with all elements from this book\n",
    "        book = epub_text_extract_from_file(file_path)\n",
    "        \n",
    "        # Skip empty DataFrames\n",
    "        if book.empty:\n",
    "            print(f\"Warning: No content extracted from {file}\")\n",
    "            continue\n",
    "        \n",
    "        # Create the CSV filename by replacing .epub extension with .csv\n",
    "        # str(file)[:-5] removes the last 5 characters (.epub)\n",
    "        csv_file_name = str(file)[:-5] + '.csv'\n",
    "        \n",
    "        # Construct the full path for the output CSV file\n",
    "        csv_file_path = os.path.join(arrival_folder, csv_file_name)\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        # index=False prevents pandas from writing row numbers as a column\n",
    "        book.to_csv(csv_file_path, index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Catch and report any errors during processing\n",
    "        # This prevents one bad file from stopping the entire batch\n",
    "        print(f\"Error processing {file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469de165-ef08-4386-bed9-37544820c1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
